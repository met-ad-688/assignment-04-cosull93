{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "59dbf35f-6c81-474c-b4e7-809545e84f23",
      "metadata": {},
      "source": [
        "# Assignment 04\n",
        "\n",
        "Caroline O’Sullivan (Boston University)  \n",
        "September 27, 2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d6f8bd02",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "25/10/08 23:17:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "25/10/08 23:17:37 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n",
            "|                  ID|LAST_UPDATED_DATE|LAST_UPDATED_TIMESTAMP|DUPLICATES|  POSTED|  EXPIRED|DURATION|        SOURCE_TYPES|             SOURCES|                 URL|ACTIVE_URLS|ACTIVE_SOURCES_INFO|           TITLE_RAW|                BODY|MODELED_EXPIRED|MODELED_DURATION| COMPANY|        COMPANY_NAME|COMPANY_RAW|COMPANY_IS_STAFFING|EDUCATION_LEVELS|EDUCATION_LEVELS_NAME|MIN_EDULEVELS| MIN_EDULEVELS_NAME|MAX_EDULEVELS|MAX_EDULEVELS_NAME|EMPLOYMENT_TYPE|EMPLOYMENT_TYPE_NAME|MIN_YEARS_EXPERIENCE|MAX_YEARS_EXPERIENCE|IS_INTERNSHIP|SALARY|REMOTE_TYPE|REMOTE_TYPE_NAME|ORIGINAL_PAY_PERIOD|SALARY_TO|SALARY_FROM|            LOCATION|                CITY|    CITY_NAME|COUNTY|   COUNTY_NAME|  MSA|            MSA_NAME|STATE|STATE_NAME|COUNTY_OUTGOING|COUNTY_NAME_OUTGOING|COUNTY_INCOMING|COUNTY_NAME_INCOMING|MSA_OUTGOING|   MSA_NAME_OUTGOING|MSA_INCOMING|   MSA_NAME_INCOMING|NAICS2|         NAICS2_NAME|NAICS3|         NAICS3_NAME|NAICS4|         NAICS4_NAME|NAICS5|         NAICS5_NAME|NAICS6|         NAICS6_NAME|             TITLE|         TITLE_NAME|         TITLE_CLEAN|              SKILLS|         SKILLS_NAME|  SPECIALIZED_SKILLS|SPECIALIZED_SKILLS_NAME|      CERTIFICATIONS| CERTIFICATIONS_NAME|       COMMON_SKILLS|  COMMON_SKILLS_NAME|     SOFTWARE_SKILLS|SOFTWARE_SKILLS_NAME|      ONET|           ONET_NAME| ONET_2019|      ONET_2019_NAME|                CIP6|           CIP6_NAME|                CIP4|           CIP4_NAME|                CIP2|           CIP2_NAME|SOC_2021_2|     SOC_2021_2_NAME|SOC_2021_3|     SOC_2021_3_NAME|SOC_2021_4|SOC_2021_4_NAME|SOC_2021_5|SOC_2021_5_NAME|LOT_CAREER_AREA|LOT_CAREER_AREA_NAME|LOT_OCCUPATION| LOT_OCCUPATION_NAME|LOT_SPECIALIZED_OCCUPATION|LOT_SPECIALIZED_OCCUPATION_NAME|LOT_OCCUPATION_GROUP|LOT_OCCUPATION_GROUP_NAME|LOT_V6_SPECIALIZED_OCCUPATION|LOT_V6_SPECIALIZED_OCCUPATION_NAME|LOT_V6_OCCUPATION|LOT_V6_OCCUPATION_NAME|LOT_V6_OCCUPATION_GROUP|LOT_V6_OCCUPATION_GROUP_NAME|LOT_V6_CAREER_AREA|LOT_V6_CAREER_AREA_NAME|  SOC_2|          SOC_2_NAME|  SOC_3|          SOC_3_NAME|  SOC_4|     SOC_4_NAME|  SOC_5|     SOC_5_NAME|LIGHTCAST_SECTORS|LIGHTCAST_SECTORS_NAME|NAICS_2022_2|   NAICS_2022_2_NAME|NAICS_2022_3|   NAICS_2022_3_NAME|NAICS_2022_4|   NAICS_2022_4_NAME|NAICS_2022_5|   NAICS_2022_5_NAME|NAICS_2022_6|   NAICS_2022_6_NAME|\n",
            "+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n",
            "|1f57d95acf4dc67ed...|         9/6/2024|  2024-09-06 20:32:...|         0|6/2/2024| 6/8/2024|       6|   [\\n  \"Company\"\\n]|[\\n  \"brassring.c...|[\\n  \"https://sjo...|         []|               NULL|Enterprise Analys...|31-May-2024\\n\\nEn...|       6/8/2024|               6|  894731|          Murphy USA| Murphy USA|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (> 32 h...|                   2|                   2|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.20...|RWwgRG9yYWRvLCBBUg==|El Dorado, AR|  5139|     Union, AR|20980|       El Dorado, AR|    5|  Arkansas|           5139|           Union, AR|           5139|           Union, AR|       20980|       El Dorado, AR|       20980|       El Dorado, AR|    44|        Retail Trade|   441|Motor Vehicle and...|  4413|Automotive Parts,...| 44133|Automotive Parts ...|441330|Automotive Parts ...|ET29C073C03D1F86B4|Enterprise Analysts|enterprise analys...|[\\n  \"KS126DB6T06...|[\\n  \"Merchandisi...|[\\n  \"KS126DB6T06...|   [\\n  \"Merchandisi...|                  []|                  []|[\\n  \"KS126706DPF...|[\\n  \"Mathematics...|[\\n  \"KS440W865GC...|[\\n  \"SQL (Progra...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|[\\n  \"45.0601\",\\n...|[\\n  \"Economics, ...|[\\n  \"45.06\",\\n  ...|[\\n  \"Economics\",...|[\\n  \"45\",\\n  \"27...|[\\n  \"Social Scie...|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101011|           General ERP Analy...|                2310|     Business Intellig...|                     23101011|              General ERP Analy...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  7\\n]|  [\\n  \"Artificial ...|          44|        Retail Trade|         441|Motor Vehicle and...|        4413|Automotive Parts,...|       44133|Automotive Parts ...|      441330|Automotive Parts ...|\n",
            "|0cb072af26757b6c4...|         8/2/2024|  2024-08-02 17:08:...|         0|6/2/2024| 8/1/2024|    NULL| [\\n  \"Job Board\"\\n]| [\\n  \"maine.gov\"\\n]|[\\n  \"https://job...|         []|               NULL|Oracle Consultant...|Oracle Consultant...|       8/1/2024|            NULL|  133098|Smx Corporation L...|        SMX|               true|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (> 32 h...|                   3|                   3|        false|  NULL|          1|          Remote|               NULL|     NULL|       NULL|{\\n  \"lat\": 44.31...|    QXVndXN0YSwgTUU=|  Augusta, ME| 23011|  Kennebec, ME|12300|Augusta-Watervill...|   23|     Maine|          23011|        Kennebec, ME|          23011|        Kennebec, ME|       12300|Augusta-Watervill...|       12300|Augusta-Watervill...|    56|Administrative an...|   561|Administrative an...|  5613| Employment Services| 56132|Temporary Help Se...|561320|Temporary Help Se...|ET21DDA63780A7DC09| Oracle Consultants|oracle consultant...|[\\n  \"KS122626T55...|[\\n  \"Procurement...|[\\n  \"KS122626T55...|   [\\n  \"Procurement...|                  []|                  []|                  []|                  []|[\\n  \"BGSBF3F508F...|[\\n  \"Oracle Busi...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          56|Administrative an...|         561|Administrative an...|        5613| Employment Services|       56132|Temporary Help Se...|      561320|Temporary Help Se...|\n",
            "|85318b12b3331fa49...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024| 7/7/2024|      35| [\\n  \"Job Board\"\\n]|[\\n  \"dejobs.org\"\\n]|[\\n  \"https://dej...|         []|               NULL|        Data Analyst|Taking care of pe...|      6/10/2024|               8|39063746|            Sedgwick|   Sedgwick|              false|       [\\n  2\\n]| [\\n  \"Bachelor's ...|            2|  Bachelor's degree|         NULL|              NULL|              1|Full-time (> 32 h...|                   5|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 32.77...|    RGFsbGFzLCBUWA==|   Dallas, TX| 48113|    Dallas, TX|19100|Dallas-Fort Worth...|   48|     Texas|          48113|          Dallas, TX|          48113|          Dallas, TX|       19100|Dallas-Fort Worth...|       19100|Dallas-Fort Worth...|    52|Finance and Insur...|   524|Insurance Carrier...|  5242|Agencies, Brokera...| 52429|Other Insurance R...|524291|    Claims Adjusting|ET3037E0C947A02404|      Data Analysts|        data analyst|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"ESF3939CE1F...|   [\\n  \"Exception R...|[\\n  \"KS683TN76T7...|[\\n  \"Security Cl...|[\\n  \"KS1218W78FG...|[\\n  \"Management\"...|[\\n  \"KS126HY6YLT...|[\\n  \"Microsoft O...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          52|Finance and Insur...|         524|Insurance Carrier...|        5242|Agencies, Brokera...|       52429|Other Insurance R...|      524291|    Claims Adjusting|\n",
            "|1b5c3941e54a1889e...|         9/6/2024|  2024-09-06 20:32:...|         1|6/2/2024|7/20/2024|      48| [\\n  \"Job Board\"\\n]|[\\n  \"disabledper...|[\\n  \"https://www...|         []|               NULL|Sr. Lead Data Mgm...|About this role:\\...|      6/12/2024|              10|37615159|         Wells Fargo|Wells Fargo|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              1|Full-time (> 32 h...|                   3|                NULL|        false|  NULL|          0|          [None]|               NULL|     NULL|       NULL|{\\n  \"lat\": 33.44...|    UGhvZW5peCwgQVo=|  Phoenix, AZ|  4013|  Maricopa, AZ|38060|Phoenix-Mesa-Chan...|    4|   Arizona|           4013|        Maricopa, AZ|           4013|        Maricopa, AZ|       38060|Phoenix-Mesa-Chan...|       38060|Phoenix-Mesa-Chan...|    52|Finance and Insur...|   522|Credit Intermedia...|  5221|Depository Credit...| 52211|  Commercial Banking|522110|  Commercial Banking|ET2114E0404BA30075|Management Analysts|sr lead data mgmt...|[\\n  \"KS123QX62QY...|[\\n  \"Exit Strate...|[\\n  \"KS123QX62QY...|   [\\n  \"Exit Strate...|                  []|                  []|[\\n  \"KS7G6NP6R6L...|[\\n  \"Reliability...|[\\n  \"KS4409D76NW...|[\\n  \"SAS (Softwa...|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231113|Data / Data Minin...|                  23111310|                   Data Analyst|                2311|     Data Analysis and...|                     23111310|                      Data Analyst|           231113|  Data / Data Minin...|                   2311|        Data Analysis and...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|        [\\n  6\\n]|  [\\n  \"Data Privac...|          52|Finance and Insur...|         522|Credit Intermedia...|        5221|Depository Credit...|       52211|  Commercial Banking|      522110|  Commercial Banking|\n",
            "|cb5ca25f02bdf25c1...|        6/19/2024|   2024-06-19 07:00:00|         0|6/2/2024|6/17/2024|      15|[\\n  \"FreeJobBoar...|[\\n  \"craigslist....|[\\n  \"https://mod...|         []|               NULL|Comisiones de $10...|Comisiones de $10...|      6/17/2024|              15|       0|        Unclassified|      LH/GM|              false|      [\\n  99\\n]| [\\n  \"No Educatio...|           99|No Education Listed|         NULL|              NULL|              3|Part-time / full-...|                NULL|                NULL|        false| 92500|          0|          [None]|               year|   150000|      35000|{\\n  \"lat\": 37.63...|    TW9kZXN0bywgQ0E=|  Modesto, CA|  6099|Stanislaus, CA|33700|         Modesto, CA|    6|California|           6099|      Stanislaus, CA|           6099|      Stanislaus, CA|       33700|         Modesto, CA|       33700|         Modesto, CA|    99|Unclassified Indu...|   999|Unclassified Indu...|  9999|Unclassified Indu...| 99999|Unclassified Indu...|999999|Unclassified Indu...|ET0000000000000000|       Unclassified|comisiones de por...|                  []|                  []|                  []|                     []|                  []|                  []|                  []|                  []|                  []|                  []|15-2051.01|Business Intellig...|15-2051.01|Business Intellig...|                  []|                  []|                  []|                  []|                  []|                  []|   15-0000|Computer and Math...|   15-2000|Mathematical Scie...|   15-2050|Data Scientists|   15-2051|Data Scientists|             23|Information Techn...|        231010|Business Intellig...|                  23101012|           Oracle Consultant...|                2310|     Business Intellig...|                     23101012|              Oracle Consultant...|           231010|  Business Intellig...|                   2310|        Business Intellig...|                23|   Information Techn...|15-0000|Computer and Math...|15-2000|Mathematical Scie...|15-2050|Data Scientists|15-2051|Data Scientists|             NULL|                  NULL|          99|Unclassified Indu...|         999|Unclassified Indu...|        9999|Unclassified Indu...|       99999|Unclassified Indu...|      999999|Unclassified Indu...|\n",
            "+--------------------+-----------------+----------------------+----------+--------+---------+--------+--------------------+--------------------+--------------------+-----------+-------------------+--------------------+--------------------+---------------+----------------+--------+--------------------+-----------+-------------------+----------------+---------------------+-------------+-------------------+-------------+------------------+---------------+--------------------+--------------------+--------------------+-------------+------+-----------+----------------+-------------------+---------+-----------+--------------------+--------------------+-------------+------+--------------+-----+--------------------+-----+----------+---------------+--------------------+---------------+--------------------+------------+--------------------+------------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------+--------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+----------+--------------------+----------+---------------+----------+---------------+---------------+--------------------+--------------+--------------------+--------------------------+-------------------------------+--------------------+-------------------------+-----------------------------+----------------------------------+-----------------+----------------------+-----------------------+----------------------------+------------------+-----------------------+-------+--------------------+-------+--------------------+-------+---------------+-------+---------------+-----------------+----------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(45)\n",
        "\n",
        "pio.renderers.default = \"notebook+notebook_connected+vscode\"\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "# Load Data\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n",
        "\n",
        "# Show Schema and Sample Data\n",
        "#print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "\n",
        "# df.printSchema() # comment this line when rendering the submission\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09cf6641",
      "metadata": {},
      "source": [
        "##Feature Engineering\n",
        "Feature Engineering is a crucial step in preparing your data for machine learning. In this lab, we will focus on the following tasks:\n",
        "\n",
        "1. Drop rows with missing values in the target variable and key features.\n",
        "2. By now you are already familiar with the code and the data. Based on your understanding please choose any 3 (my code output has 10) variables as:\n",
        "three continuous variables and, MIN_YEARS_EXPERIENCE (total 4, use your best judgment!)\n",
        "two categorical .\n",
        "Your dependent variable (y) is SALARY.\n",
        "3. Convert categorical variables into numerical representations using StringIndexer and OneHotEncoder.\n",
        "4. Assemble features into a single vector using VectorAssembler.\n",
        "5. Split the data into training and testing sets.\n",
        "6. You can use pipeline to do the above steps in one go.\n",
        "7. Create a new column MIN_YEARS_EXPERIENCE_SQ by squaring the MIN_YEARS_EXPERIENCE column.\n",
        "8. Assemble the polynomial features into a new vector column features_poly using VectorAssembler.\n",
        "9. Show the final structure of the DataFrame with the new features.\n",
        "#Missing Value Treatment\n",
        "1. Replace missing values in Salary by Median of Salary based on the Employment Type, if missing then replace with the overall median of Salary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c0dd32c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#Missing Value Treatment\n",
        "#1. Replace missing values in Salary by Median of Salary based on the Employment Type, if missing then replace with the overall median of Salary\n",
        "\n",
        "from pyspark.sql import Window\n",
        "from pyspark.sql.functions import col, when, isnan, count, lit, expr, avg, median, pow\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "\n",
        "#select subset of columns\n",
        "eda_cols = [\"SALARY\",\"MIN_YEARS_EXPERIENCE\",\"EMPLOYMENT_TYPE_NAME\",\"REMOTE_TYPE_NAME\",\"STATE_NAME\",\"MIN_EDULEVELS_NAME\",\"COMPANY_IS_STAFFING\",\"IS_INTERNSHIP\"]\n",
        "df_subset = df.select(eda_cols)\n",
        "\n",
        "#Fix Remote Type Name incorrect labels to Remote, Hybrid, Onsite.  None and NULL are Onsite.\n",
        "df_subset = df_subset.withColumn(\n",
        "    \"REMOTE_TYPE_NAME\",\n",
        "    when(col(\"REMOTE_TYPE_NAME\") == \"Remote\", \"Remote\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"Not Remote\", \"On Site\")\n",
        "    .when(col(\"REMOTE_TYPE_NAME\") == \"Hybrid Remote\", \"Hybrid\")\n",
        "    .when((col(\"REMOTE_TYPE_NAME\").isNull()) | (col(\"REMOTE_TYPE_NAME\") == \"[None]\"), \"On Site\")\n",
        "    .otherwise(\"On Site\")\n",
        ")\n",
        "\n",
        "#Clean Employment Type\n",
        "df_subset = df_subset.withColumn(\n",
        "    \"EMPLOYMENT_TYPE_NAME\",\n",
        "    when(col(\"EMPLOYMENT_TYPE_NAME\").like(\"Part-time (â‰¤ 32%\"), \"Part Time\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\").like(\"Part-time / full-%\"), \"Flexible\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\").like(\"Full-time (> 32%\"), \"Full Time\")\n",
        "    .when(col(\"EMPLOYMENT_TYPE_NAME\").isNull(), \"Full Time\")\n",
        "    .otherwise(\"Full Time\")  # fallback for anything else\n",
        ")\n",
        "#Calculate the median of MIN_YEARS_EXPERIENCE column based on Employment Type\n",
        "median_by_emp_type_min_exp = df.groupBy(\"EMPLOYMENT_TYPE\").agg(expr('percentile_approx(MIN_YEARS_EXPERIENCE, 0.5)').alias('median_min_years_experience_by_emp_type'))\n",
        "\n",
        "#Median Salary\n",
        "median_salary = df_subset.approxQuantile(\"SALARY\", [0.5], 0.25)[0]\n",
        "median_by_emp_type = (\n",
        "    df_subset.groupBy(\"EMPLOYMENT_TYPE_NAME\")\n",
        "    .agg(expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary_by_emp_type\"))\n",
        ")\n",
        "\n",
        "df_subset = df_subset.join(median_by_emp_type, on=\"EMPLOYMENT_TYPE_NAME\", how=\"left\")\n",
        "df_subset = df_subset.withColumn(\n",
        "    \"SALARY\",\n",
        "    when(\n",
        "        col(\"SALARY\").isNull(),\n",
        "        when(col(\"median_salary_by_emp_type\").isNotNull(), col(\"median_salary_by_emp_type\"))\n",
        "        .otherwise(lit(median_salary))\n",
        "    ).otherwise(col(\"SALARY\"))\n",
        ").drop(\"median_salary_by_emp_type\")\n",
        "\n",
        "#Median MIN_YEARS_EXPERIENCE\n",
        "median_by_emp_type_min_exp = df.groupBy(\"EMPLOYMENT_TYPE_NAME\").agg(\n",
        "    expr('percentile_approx(MIN_YEARS_EXPERIENCE, 0.5)').alias('median_min_years_experience_by_emp_type')\n",
        ")\n",
        "df_subset = df_subset.join(median_by_emp_type_min_exp, on=\"EMPLOYMENT_TYPE_NAME\", how=\"left\")\n",
        "df_subset = df_subset.withColumn(\n",
        "    \"MIN_YEARS_EXPERIENCE\",\n",
        "    when(\n",
        "        col(\"MIN_YEARS_EXPERIENCE\").isNull(),\n",
        "        when(col(\"median_min_years_experience_by_emp_type\").isNotNull(), col(\"median_min_years_experience_by_emp_type\"))\n",
        "        .otherwise(lit(0))  # fallback if needed\n",
        "    ).otherwise(col(\"MIN_YEARS_EXPERIENCE\"))\n",
        ").drop(\"median_min_years_experience_by_emp_type\")\n",
        "\n",
        "#False for IS_INTERNSHIP and COMPANY_IS_STAFFING if NULL\n",
        "df_subset = df_subset.withColumn(\n",
        "    \"IS_INTERNSHIP\",\n",
        "    when(col(\"IS_INTERNSHIP\").isNull(), lit(False)).otherwise(col(\"IS_INTERNSHIP\"))\n",
        ").withColumn(\n",
        "    \"COMPANY_IS_STAFFING\",\n",
        "    when(col(\"COMPANY_IS_STAFFING\").isNull(), lit(False)).otherwise(col(\"COMPANY_IS_STAFFING\"))\n",
        ")\n",
        "\n",
        "df_subset = df_subset.withColumn(\"IS_INTERNSHIP_num\", col(\"IS_INTERNSHIP\").cast(\"int\"))\n",
        "df_subset = df_subset.withColumn(\"COMPANY_IS_STAFFING_num\", col(\"COMPANY_IS_STAFFING\").cast(\"int\"))\n",
        "\n",
        "df_subset = df_subset.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "403b35ea",
      "metadata": {},
      "source": [
        "Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "286771d2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#Feature Engineering\n",
        "#String Indexing and One Hot Encoding for Categorical Variables\n",
        "categorical_cols = [\"EMPLOYMENT_TYPE_NAME\",\"REMOTE_TYPE_NAME\",\"MIN_EDULEVELS_NAME\",\"STATE_NAME\"]\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_idx\", handleInvalid='skip') for col in categorical_cols]\n",
        "encoders = [OneHotEncoder(inputCol=f\"{col}_idx\", outputCol=f\"{col}_vec\") for col in categorical_cols]\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        \"MIN_YEARS_EXPERIENCE\",\n",
        "        \"COMPANY_IS_STAFFING\",\n",
        "        \"IS_INTERNSHIP\"\n",
        "    ] + [f\"{col}_vec\" for col in categorical_cols],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
        "data = pipeline.fit(df_subset).transform(df_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3d7dcbe3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 48:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------+------------------------------------------------------------------------------------------------------------------+--------+\n",
            "|features                               |normFeatures                                                                                                      |SALARY  |\n",
            "+---------------------------------------+------------------------------------------------------------------------------------------------------------------+--------+\n",
            "|(62,[0,4,5,7,23],[3.0,1.0,1.0,1.0,1.0])|(62,[0,4,5,7,23],[0.8320502943378437,0.2773500981126146,0.2773500981126146,0.2773500981126146,0.2773500981126146])|103573.0|\n",
            "|(62,[4,5,8,16],[1.0,1.0,1.0,1.0])      |(62,[4,5,8,16],[0.5,0.5,0.5,0.5])                                                                                 |86390.0 |\n",
            "|(62,[0,4,5,7,22],[3.0,1.0,1.0,1.0,1.0])|(62,[0,4,5,7,22],[0.8320502943378437,0.2773500981126146,0.2773500981126146,0.2773500981126146,0.2773500981126146])|86390.0 |\n",
            "|(62,[4,5,7,16],[1.0,1.0,1.0,1.0])      |(62,[4,5,7,16],[0.5,0.5,0.5,0.5])                                                                                 |52987.0 |\n",
            "|(62,[4,6,8,20],[1.0,1.0,1.0,1.0])      |(62,[4,6,8,20],[0.5,0.5,0.5,0.5])                                                                                 |86390.0 |\n",
            "+---------------------------------------+------------------------------------------------------------------------------------------------------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#Normalize Features\n",
        "from pyspark.ml.feature import Normalizer\n",
        "\n",
        "normalizer = Normalizer(inputCol=\"features\",outputCol=\"normFeatures\",p=2.0)\n",
        "\n",
        "# Apply normalization\n",
        "data_normalized = normalizer.transform(data)\n",
        "\n",
        "# Optional: view results\n",
        "data_normalized.select(\"features\", \"normFeatures\", \"SALARY\").show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f7ee8fd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Test Train Split\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "51db6020",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.regression import GeneralizedLinearRegression\n",
        "from pyspark.sql import Row\n",
        "\n",
        "feature_names = assembler.getInputCols()\n",
        "\n",
        "glr = GeneralizedLinearRegression(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"SALARY\",\n",
        "    family=\"gaussian\",\n",
        "    link=\"identity\",\n",
        "    maxIter=10,\n",
        "    regParam=0.3,\n",
        ")\n",
        "\n",
        "glr_model = glr.fit(train_data)\n",
        "glr_summary = glr_model.summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "daf3a2d0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intercept: 102278.9407\n",
            "Coefficients:\n",
            " Feature 1: 2378.7010\n",
            " Feature 2: -2835.2513\n",
            " Feature 3: -3435.8114\n",
            " Feature 4: 12006.3027\n",
            " Feature 5: -8290.8537\n",
            " Feature 6: 1538.9051\n",
            " Feature 7: 1088.4958\n",
            " Feature 8: -5950.0787\n",
            " Feature 9: -3615.2379\n",
            " Feature 10: -22564.1717\n",
            " Feature 11: -11979.7180\n",
            " Feature 12: 6353.9330\n",
            " Feature 13: -1553.1378\n",
            " Feature 14: 2688.0705\n",
            " Feature 15: -2274.1549\n",
            " Feature 16: 490.1882\n",
            " Feature 17: 576.8265\n",
            " Feature 18: -164.8164\n",
            " Feature 19: -1131.9933\n",
            " Feature 20: -1786.4970\n",
            " Feature 21: -2290.7826\n",
            " Feature 22: 1624.7187\n",
            " Feature 23: -2157.5368\n",
            " Feature 24: 2.7998\n",
            " Feature 25: -687.9366\n",
            " Feature 26: -2652.3943\n",
            " Feature 27: 3176.2818\n",
            " Feature 28: -1391.5348\n",
            " Feature 29: -3838.0329\n",
            " Feature 30: -2622.0994\n",
            " Feature 31: -1952.8745\n",
            " Feature 32: -1542.7176\n",
            " Feature 33: -641.1122\n",
            " Feature 34: -3499.4323\n",
            " Feature 35: -930.2304\n",
            " Feature 36: -996.0715\n",
            " Feature 37: 2871.9190\n",
            " Feature 38: -2375.4212\n",
            " Feature 39: -2173.8021\n",
            " Feature 40: -1138.4543\n",
            " Feature 41: -4351.5362\n",
            " Feature 42: -1842.2851\n",
            " Feature 43: -1461.6578\n",
            " Feature 44: -1012.8358\n",
            " Feature 45: -6805.4274\n",
            " Feature 46: 2939.3664\n",
            " Feature 47: -1612.1046\n",
            " Feature 48: -2197.0598\n",
            " Feature 49: -3211.0793\n",
            " Feature 50: -760.8950\n",
            " Feature 51: -226.1467\n",
            " Feature 52: -78.5807\n",
            " Feature 53: -3717.8571\n",
            " Feature 54: -4033.0228\n",
            " Feature 55: -7850.0135\n",
            " Feature 56: -4341.2085\n",
            " Feature 57: -9986.9455\n",
            " Feature 58: -7546.0152\n",
            " Feature 59: 3243.1689\n",
            " Feature 60: 811.4712\n",
            " Feature 61: -7436.7514\n",
            " Feature 62: -10989.4340\n"
          ]
        }
      ],
      "source": [
        "#Model Summary\n",
        "\n",
        "print(\"Intercept: {:.4f}\".format(glr_model.intercept))\n",
        "print(\"Coefficients:\")\n",
        "for i, coef in enumerate(glr_model.coefficients):\n",
        "    print(f\" Feature {i + 1}: {coef:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "194c9967",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 64:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coefficient Standard Errors: ['32.1098', '345.5202', '758.5322', '998.1229', '1182.6848', '667.5953', '711.0274', '2935.8109', '2938.5952', '2974.3190', '2986.2789', '3017.8056', '3103.7287', '3105.9301', '3125.4587', '3126.0381', '3126.9004', '3129.9410', '3139.8876', '3141.4249', '3143.4861', '3143.4611', '3153.0125', '3157.2838', '3167.5916', '3177.9271', '3177.1376', '3188.2625', '3189.0496', '3192.7196', '3202.2389', '3205.5528', '3208.6622', '3227.4155', '3228.2393', '3244.4764', '3257.6197', '3281.2210', '3307.3549', '3317.3929', '3315.0877', '3323.9190', '3323.6527', '3334.4591', '3339.7964', '3331.9678', '3364.9221', '3402.6602', '3400.3004', '3395.5481', '3402.1817', '3423.3624', '3502.2973', '3560.7282', '3596.8296', '3635.7330', '3648.5880', '3711.9215', '3718.6007', '3826.0438', '3879.8121', '4034.6588', '4397.4497']\n",
            "T Values: ['74.0801', '-8.2057', '-4.5296', '12.0289', '-7.0102', '2.3051', '1.5309', '-2.0267', '-1.2303', '-7.5863', '-4.0116', '2.1055', '-0.5004', '0.8655', '-0.7276', '0.1568', '0.1845', '-0.0527', '-0.3605', '-0.5687', '-0.7287', '0.5169', '-0.6843', '0.0009', '-0.2172', '-0.8346', '0.9997', '-0.4365', '-1.2035', '-0.8213', '-0.6098', '-0.4813', '-0.1998', '-1.0843', '-0.2882', '-0.3070', '0.8816', '-0.7239', '-0.6573', '-0.3432', '-1.3126', '-0.5543', '-0.4398', '-0.3037', '-2.0377', '0.8822', '-0.4791', '-0.6457', '-0.9444', '-0.2241', '-0.0665', '-0.0230', '-1.0615', '-1.1326', '-2.1825', '-1.1940', '-2.7372', '-2.0329', '0.8721', '0.2121', '-1.9168', '-2.7238', '23.2587']\n",
            "P Values: ['0.0000', '0.0000', '0.0000', '0.0000', '0.0000', '0.0212', '0.1258', '0.0427', '0.2186', '0.0000', '0.0001', '0.0353', '0.6168', '0.3868', '0.4668', '0.8754', '0.8536', '0.9580', '0.7185', '0.5696', '0.4662', '0.6053', '0.4938', '0.9993', '0.8281', '0.4039', '0.3174', '0.6625', '0.2288', '0.4115', '0.5420', '0.6303', '0.8416', '0.2782', '0.7732', '0.7588', '0.3780', '0.4691', '0.5110', '0.7315', '0.1893', '0.5794', '0.6601', '0.7613', '0.0416', '0.3777', '0.6319', '0.5185', '0.3450', '0.8227', '0.9470', '0.9817', '0.2884', '0.2574', '0.0291', '0.2325', '0.0062', '0.0421', '0.3831', '0.8320', '0.0553', '0.0065', '0.0000']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#Summary Statistics\n",
        "print(\"Coefficient Standard Errors:\", [f\"{val:.4f}\" for val in glr_summary.coefficientStandardErrors])\n",
        "print(\"T Values:\", [f\"{val:.4f}\" for val in glr_summary.tValues])\n",
        "print(\"P Values:\", [f\"{val:.4f}\" for val in glr_summary.pValues])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0006d3fa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null Deviance: 51607738345410.0703\n",
            "Residual DF Null: 57956\n",
            "Residual DF: 57894\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 81:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIC: 1350095.6573\n",
            "Deviance: 44306505655818.4141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#Dispersion\n",
        "print(f\"Null Deviance: {glr_summary.nullDeviance:.4f}\")\n",
        "print(f\"Residual DF Null: {glr_summary.residualDegreeOfFreedomNull}\")\n",
        "print(f\"Residual DF: {glr_summary.residualDegreeOfFreedom}\")\n",
        "print(f\"AIC: {glr_summary.aic:.4f}\")\n",
        "print(f\"Deviance: {glr_summary.deviance:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e35628cb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of features: 63\n",
            "Length of coefficients: 63\n",
            "Length of standard errors: 63\n",
            "Length of t-values: 63\n",
            "Length of p-values: 63\n"
          ]
        }
      ],
      "source": [
        "feature_names = glr_summary._call_java(\"featureNames\")\n",
        "features = [\"Intercept\"] + feature_names\n",
        "coefs = [glr_model.intercept] + list(glr_model.coefficients)\n",
        "se = list(glr_summary.coefficientStandardErrors)\n",
        "t_values = list(glr_summary.tValues)\n",
        "p_values = list(glr_summary.pValues)\n",
        "\n",
        "print(\"Length of features:\", len(features))\n",
        "print(\"Length of coefficients:\", len(coefs))\n",
        "print(\"Length of standard errors:\", len(se))\n",
        "print(\"Length of t-values:\", len(t_values))\n",
        "print(\"Length of p-values:\", len(p_values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "89dfad33",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Estimate</th>\n",
              "      <th>Std. Error</th>\n",
              "      <th>t-value</th>\n",
              "      <th>p-value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Intercept</td>\n",
              "      <td>102278.9407</td>\n",
              "      <td>32.1098</td>\n",
              "      <td>74.0801</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MIN_YEARS_EXPERIENCE</td>\n",
              "      <td>2378.7010</td>\n",
              "      <td>345.5202</td>\n",
              "      <td>-8.2057</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>COMPANY_IS_STAFFING</td>\n",
              "      <td>-2835.2513</td>\n",
              "      <td>758.5322</td>\n",
              "      <td>-4.5296</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IS_INTERNSHIP</td>\n",
              "      <td>-3435.8114</td>\n",
              "      <td>998.1229</td>\n",
              "      <td>12.0289</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EMPLOYMENT_TYPE_NAME_vec_Full Time</td>\n",
              "      <td>12006.3027</td>\n",
              "      <td>1182.6848</td>\n",
              "      <td>-7.0102</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>STATE_NAME_vec_Alaska</td>\n",
              "      <td>-7546.0152</td>\n",
              "      <td>3718.6007</td>\n",
              "      <td>0.8721</td>\n",
              "      <td>0.3831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>STATE_NAME_vec_Vermont</td>\n",
              "      <td>3243.1689</td>\n",
              "      <td>3826.0438</td>\n",
              "      <td>0.2121</td>\n",
              "      <td>0.8320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>STATE_NAME_vec_Montana</td>\n",
              "      <td>811.4712</td>\n",
              "      <td>3879.8121</td>\n",
              "      <td>-1.9168</td>\n",
              "      <td>0.0553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>STATE_NAME_vec_West Virginia</td>\n",
              "      <td>-7436.7514</td>\n",
              "      <td>4034.6588</td>\n",
              "      <td>-2.7238</td>\n",
              "      <td>0.0065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>STATE_NAME_vec_North Dakota</td>\n",
              "      <td>-10989.4340</td>\n",
              "      <td>4397.4497</td>\n",
              "      <td>23.2587</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Feature     Estimate Std. Error  t-value  \\\n",
              "0                            Intercept  102278.9407    32.1098  74.0801   \n",
              "1                 MIN_YEARS_EXPERIENCE    2378.7010   345.5202  -8.2057   \n",
              "2                  COMPANY_IS_STAFFING   -2835.2513   758.5322  -4.5296   \n",
              "3                        IS_INTERNSHIP   -3435.8114   998.1229  12.0289   \n",
              "4   EMPLOYMENT_TYPE_NAME_vec_Full Time   12006.3027  1182.6848  -7.0102   \n",
              "..                                 ...          ...        ...      ...   \n",
              "58               STATE_NAME_vec_Alaska   -7546.0152  3718.6007   0.8721   \n",
              "59              STATE_NAME_vec_Vermont    3243.1689  3826.0438   0.2121   \n",
              "60              STATE_NAME_vec_Montana     811.4712  3879.8121  -1.9168   \n",
              "61        STATE_NAME_vec_West Virginia   -7436.7514  4034.6588  -2.7238   \n",
              "62         STATE_NAME_vec_North Dakota  -10989.4340  4397.4497  23.2587   \n",
              "\n",
              "   p-value  \n",
              "0   0.0000  \n",
              "1   0.0000  \n",
              "2   0.0000  \n",
              "3   0.0000  \n",
              "4   0.0000  \n",
              "..     ...  \n",
              "58  0.3831  \n",
              "59  0.8320  \n",
              "60  0.0553  \n",
              "61  0.0065  \n",
              "62  0.0000  \n",
              "\n",
              "[63 rows x 5 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from IPython.display import HTML\n",
        "\n",
        "summary_df = pd.DataFrame({\n",
        "    \"Feature\": features,\n",
        "    \"Estimate\": [f\"{v:.4f}\" if v is not None else None for v in coefs],\n",
        "    \"Std. Error\": [f\"{v:.4f}\" if v is not None else None for v in se],\n",
        "    \"t-value\": [f\"{v:.4f}\" if v is not None else None for v in t_values],\n",
        "    \"p-value\": [f\"{v:.4f}\" if v is not None else None for v in p_values]\n",
        "})\n",
        "summary_df.to_csv(\"output/glr_model_summary.csv\", index=False)\n",
        "summary_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6448654f",
      "metadata": {},
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e60da721",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
